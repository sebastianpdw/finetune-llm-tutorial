{
  "run_name": "qwen-qwen-2-5-14b-instruct-4bit",
  "hyperstack_deployment": {
    "enabled": true,
    "environment_name": "default-NORWAY-1",
    "vm_name": "finetuning-norway-vm",
    "flavor_name": "n3-RTX-A4000x1",
    "keypair_name": "finetuning-norway-keypair-2",
    "image_name": "Ubuntu Server 22.04 LTS R535 CUDA 12.2 with Docker",
    "delete_after_completion": false
  },
  "finetuning": {
    "enabled": true,
    "use_host_hf_token": false,
    "model_name_or_path": "unsloth/Qwen2.5-14B-Instruct-bnb-4bit",
    "load_model_in_4bit": true,
    "dataset_csv_path": "data/datasets/train.csv",
    "num_train_epochs": 10,
    "batch_size": 4,
    "learning_rate": 5e-5,
    "gradient_accumulation_steps": 2,
    "peft": "lora",
    "peft_hyperparams": {
      "r": 16,
      "lora_alpha": 64,
      "lora_dropout": 0.1
    }
  },
  "inference": {
    "enabled": true,
    "mode": "csv",
    "mode_configs": {
      "csv": {
        "input_path": "data/datasets/test.csv",
        "input_column": "user",
        "output_column": "response"
      }
    },
    "model_hyperparams": {
      "temperature": 0.5,
      "max_length": 500
    }
  },

  "app_deployment": {
    "enabled": true,
    "use_host_hf_token": true,
    "model_run_dir": "latest",
    "base_model": "unsloth/Qwen2.5-14B-Instruct-bnb-4bit",
    "additional_vllm_args": [
      "--max-model-len 4096",
      "--gpu_memory_utilization 0.8",
      "--max-num-seqs 88",
      "--quantization bitsandbytes",
      "--load-format bitsandbytes"
    ]
  }
}
